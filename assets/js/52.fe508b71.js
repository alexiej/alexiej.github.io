(window.webpackJsonp=window.webpackJsonp||[]).push([[52],{1268:function(t,a,s){"use strict";s.r(a);var n=s(1),e=Object(n.a)({},function(){var t=this,a=t.$createElement,n=t._self._c||a;return n("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[n("h3",{attrs:{id:"convolution-network"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#convolution-network","aria-hidden":"true"}},[t._v("#")]),t._v(" Convolution Network "),n("cl",{attrs:{i:"https://medium.com/impactai/cnns-from-different-viewpoints-fab7f52d159c"}})],1),t._v(" "),n("p",[t._v("Convolution Network is type of layer in the neural network that can help you to read information about image by putting a mask (like in the most popular image software ) called kernel "),n("a",{attrs:{href:"https://en.wikipedia.org/wiki/Kernel_(image_processing)",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://en.wikipedia.org/wiki/Kernel_(image_processing)"),n("OutboundLink")],1),t._v(" . It doesnâ€™t have to bet a 3x3 matrix, but this is most popular. In the webpage "),n("a",{attrs:{href:"http://setosa.io/ev/image-kernels/",target:"_blank",rel:"noopener noreferrer"}},[t._v("http://setosa.io/ev/image-kernels/"),n("OutboundLink")],1),t._v(" you can play with the own matrix. The calculation is don for each pixel in the image. For each of them we get the matrix around the pixel with the size of the kernel (3x3) and multiply each of them.  The sum is the new pixel of the image.")]),t._v(" "),n("p",[n("img",{attrs:{src:s(214),alt:"img"}})]),t._v(" "),n("p",[t._v("For example below matrix creates from your image of cat edges around your cat.")]),t._v(" "),n("p",[n("img",{attrs:{src:s(215),alt:"1552500642360"}})]),t._v(" "),n("p",[n("img",{attrs:{src:s(216),alt:"1552500673214"}})]),t._v(" "),n("p",[n("img",{attrs:{src:s(217),alt:"1552500687431"}})]),t._v(" "),n("p",[t._v("Define different matrix you can find different factors that appear on your image.  In the popular models first layer can detect simple artifacts like edges "),n("cl",{attrs:{i:"http://cs231n.github.io/convolutional-networks/"}}),t._v(",  but next layers can go into some deeper knowledge like if this is a cat or dog, based on this artifacts.  In below example there are 96 kernels with image 11x11x3 that shows different aspects.")],1),t._v(" "),n("p",[n("img",{attrs:{src:s(218),alt:"img"}})]),t._v(" "),n("h4",{attrs:{id:"f-conv2d"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#f-conv2d","aria-hidden":"true"}},[t._v("#")]),t._v(" F.conv2d")]),t._v(" "),n("p",[t._v("In pytorch function for calculation convolution is "),n("code",[t._v("F.conv2d")]),t._v(",")]),t._v(" "),n("table",[n("thead",[n("tr",[n("th",[t._v("parameter")]),t._v(" "),n("th",[t._v("definition")])])]),t._v(" "),n("tbody",[n("tr",[n("td",[n("code",[t._v("input")])]),t._v(" "),n("td",[t._v("input data")])]),t._v(" "),n("tr",[n("td",[n("code",[t._v("weight")])]),t._v(" "),n("td",[t._v("kernel to use on the shape")])]),t._v(" "),n("tr",[n("td",[n("code",[t._v("bias")])]),t._v(" "),n("td",[t._v("optional bial")])]),t._v(" "),n("tr",[n("td",[n("code",[t._v("stride")])]),t._v(" "),n("td",[t._v("The stride of the convolving kerenl.")])]),t._v(" "),n("tr",[n("td",[n("code",[t._v("padding")])]),t._v(" "),n("td",[t._v("implicit zero padding on both sides of the input.")])]),t._v(" "),n("tr",[n("td",[n("code",[t._v("dilation")])]),t._v(" "),n("td",[t._v("the space between kernel elements")])]),t._v(" "),n("tr",[n("td",[n("code",[t._v("groups")])]),t._v(" "),n("td",[t._v("split input into groups")])])])]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("k "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tensor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("expand"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),t._v("\nF"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("conv2d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" k"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("stride"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("padding"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("full-code",[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" fastai"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vision "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("\n\npath "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" untar_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("URLs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PETS"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'images'")]),t._v("\nimg "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" path"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'japanese_chin_125.jpg'")]),t._v("\n\ndata "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" open_image"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("img"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nt "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("px "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# get item set shape: ([3, 500, 377])")]),t._v("\n\nk "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tensor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("expand"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# shape (1,3,3,3), ")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#t[None] - used to extend the shape of the tensor to [1,3,500,377]")]),t._v("\noutput "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" F"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("conv2d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("k"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                  stride"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                  padding"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#shape: ([1, 1, 500, 377])")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nshow_image"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" figsize"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])])]),t._v(" "),n("p",[n("img",{attrs:{src:s(219),alt:"1552559867051"}})]),t._v(" "),n("h4",{attrs:{id:"stride"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#stride","aria-hidden":"true"}},[t._v("#")]),t._v(" stride")]),t._v(" "),n("p",[t._v("Usual your kernel is shifted by 1 pixel ("),n("code",[t._v("stride=1")]),t._v("). Your kernel is start from the position "),n("code",[t._v("(0,0)")]),t._v(" and move to the position "),n("code",[t._v("(1,0)")]),t._v(" but you can shift the pixel by any value you want.")]),t._v(" "),n("cl",{attrs:{i:"https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/"}}),t._v(" "),n("p",[n("img",{attrs:{src:s(220),alt:"1552564165730"}})]),t._v(" "),n("p",[t._v("If you set a stride to 2 your kernell will be moved by 2 pixels, and the size of the input image will be 2 times smaller (for example for above image is  "),n("code",[t._v("[250,189]")]),t._v(").")]),t._v(" "),n("p",[n("img",{attrs:{src:s(221),alt:"1552564234896"}})]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("output "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" F"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("conv2d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("k"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                  stride"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                  padding"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#shape: ([1, 1, 500, 377])")]),t._v("\n")])])]),n("full-code",[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" fastai"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vision "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("\n\npath "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" untar_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("URLs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PETS"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'images'")]),t._v("\nimg "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" path"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'japanese_chin_125.jpg'")]),t._v("\n\ndata "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" open_image"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("img"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nt "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("px "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# get item set shape: ([3, 500, 377])")]),t._v("\n\nk "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tensor"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("  "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v("   "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("21")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("expand"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# shape (1,3,3,3), ")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#t[None] - used to extend the shape of the tensor to [1,3,500,377]")]),t._v("\noutput "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" F"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("conv2d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("k"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                  stride"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                  padding"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#shape: ([1, 1, 500, 377])")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#show_image(output[0], figsize=(5,5));")]),t._v("\n")])])])]),t._v(" "),n("h4",{attrs:{id:"padding"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#padding","aria-hidden":"true"}},[t._v("#")]),t._v(" padding")]),t._v(" "),n("p",[t._v("The default padding for function is 0. The problem is that your image will decrease in the size by 1 pixel for each corner  (if you have kernel=(3,3))")]),t._v(" "),n("p",[n("em",[t._v("[from (10,10) to (9,9)]")])]),t._v(" "),n("p",[n("img",{attrs:{src:s(222),alt:"1552565495070"}})]),t._v(" "),n("p",[t._v("To avoid this we can add padding,  increase the previous size with 0 values.")]),t._v(" "),n("p",[n("img",{attrs:{src:s(223),alt:"1552565871005"}})]),t._v(" "),n("p",[t._v("The output size is the same as the input size. For 5x5 kernel, the padding must be (2,2) to get the same size of the image.")]),t._v(" "),n("p",[n("img",{attrs:{src:s(224),alt:"1552566061084"}})]),t._v(" "),n("h4",{attrs:{id:"nn-conv2d"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#nn-conv2d","aria-hidden":"true"}},[t._v("#")]),t._v(" nn.Conv2d")]),t._v(" "),n("p",[t._v("To create a layer for your model you have a function "),n("code",[t._v("nn.Conv2d")]),t._v(",")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("n "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Conv2d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("in_channels "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              out_channels"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              kernel_size "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              padding"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" stride "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nshow_image"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("full-code",[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("n "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Conv2d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("in_channels "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              out_channels"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              kernel_size "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              padding"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n              stride "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#print(t.shape)")]),t._v("\no "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" n"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("None")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nshow_image"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("o"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("o"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n")])])])]),t._v(" "),n("p",[n("img",{attrs:{src:s(225),alt:"1552560544169"}})]),t._v(" "),n("p",[n("code",[t._v("show_image")]),t._v(" can only accept 1 channel and 3 channels, but you can create more and if you look into "),n("code",[t._v("resnet34")]),t._v(" you will find that first convolution layer has 64 channels as output, and 3 as an input.")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" fastai"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vision "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("\n\nmodel "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resnet34"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[n("img",{attrs:{src:s(226),alt:"\t\t1552567407873"}})]),t._v(" "),n("h4",{attrs:{id:"the-size-of-the-output"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#the-size-of-the-output","aria-hidden":"true"}},[t._v("#")]),t._v(" The size of the output")]),t._v(" "),n("p",[t._v("When you look into summary for your model "),n("code",[t._v("summary()")]),t._v(" in the fast.ai you will find the layers that represents convolutional network 2d and size of each layer.")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("learn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("summary"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("full-code",[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" fastai"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vision "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("\n\nbs "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("64")]),t._v("\npath "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" untar_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("URLs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PETS"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'images'")]),t._v("\n\ndata "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ImageList"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_folder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split_by_rand_pct"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" seed"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("label_from_re"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("r'([^/]+)_\\d+.jpg$'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("transform"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("get_transforms"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" size"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("224")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("databunch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bs"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("bs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("normalize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("imagenet_stats"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlearn "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cnn_learner"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                   models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resnet34"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                   metrics"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("error_rate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                   bn_final"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nlearn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("summary"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]),t._v(" "),n("p",[n("img",{attrs:{src:s(457),alt:"1552571621488"}})]),t._v(" "),n("p",[t._v("To calculate the output size of the image (width and height), you can use below formula.")]),t._v(" "),n("p",[n("img",{attrs:{src:s(227),alt:"1552571969347"}})]),t._v(" "),n("h4",{attrs:{id:"examples"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#examples","aria-hidden":"true"}},[t._v("#")]),t._v(" Examples:")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("t "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ones"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("100")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#items, channels, width, height")]),t._v("\nlayer "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Conv2d"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n          in_channels "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n          out_channels"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n          kernel_size "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n          padding"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n    \t  stride "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nlayer"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("t"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape\n")])])]),n("p",[n("code",[t._v("W = 100, H = 100, K=(3,3), P=(1,1), S=(1,1)")])]),t._v(" "),n("p",[n("code",[t._v("ow = (W-K+2P)/S + 1 = (100-3+2)/1+1=100")]),t._v(" "),n("code",[t._v("oh = (W-K+2P)/S + 1 = (100-3+2)/1+1=100")])]),t._v(" "),n("table",[n("thead",[n("tr",[n("th",[t._v("(items, channels,width,height)")]),t._v(" "),n("th",[t._v("out_channels")]),t._v(" "),n("th",[t._v("kernel")]),t._v(" "),n("th",[t._v("stride")]),t._v(" "),n("th",[t._v("padding")]),t._v(" "),n("th",[t._v("Output size")])])]),t._v(" "),n("tbody",[n("tr",[n("td",[n("code",[t._v("[1,3,100,100]")])]),t._v(" "),n("td",[n("code",[t._v("64")])]),t._v(" "),n("td",[n("code",[t._v("[3,3]")])]),t._v(" "),n("td",[n("code",[t._v("(1,1)")])]),t._v(" "),n("td",[n("code",[t._v("(1,1)")])]),t._v(" "),n("td",[n("code",[t._v("[1, 64, 100, 100]")]),n("br"),n("code",[t._v("((100-3+2*1)/1+1)")])])]),t._v(" "),n("tr",[n("td",[n("code",[t._v("[1,3,100,100]")])]),t._v(" "),n("td",[n("code",[t._v("64")])]),t._v(" "),n("td",[n("code",[t._v("[7,7]")])]),t._v(" "),n("td",[n("code",[t._v("(1,1)")])]),t._v(" "),n("td",[n("code",[t._v("(1,1)")])]),t._v(" "),n("td",[n("code",[t._v("[1,64,96,96]")]),n("br"),t._v(" "),n("code",[t._v("((100-7+2*1)/1+1)")])])]),t._v(" "),n("tr",[n("td",[n("code",[t._v("[1,3,100,100]")])]),t._v(" "),n("td",[n("code",[t._v("64")])]),t._v(" "),n("td",[n("code",[t._v("[3,3]")])]),t._v(" "),n("td",[n("code",[t._v("(2,2)")])]),t._v(" "),n("td",[n("code",[t._v("(1,1)")])]),t._v(" "),n("td",[n("code",[t._v("[1,64,50,50]")]),t._v(" "),n("br"),n("code",[t._v("((100-3+2*1)/2+1)")])])]),t._v(" "),n("tr",[n("td",[n("code",[t._v("[1,3,100,100]")])]),t._v(" "),n("td",[n("code",[t._v("64")])]),t._v(" "),n("td",[n("code",[t._v("[3,3]")])]),t._v(" "),n("td",[n("code",[t._v("(1,1)")])]),t._v(" "),n("td",[n("code",[t._v("(0,0)")])]),t._v(" "),n("td",[n("code",[t._v("[1,64,49,49]")]),t._v(" "),n("br"),n("code",[t._v("((100-3+2*1)/2+1)")])])])])]),t._v(" "),n("h4",{attrs:{id:"netron"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#netron","aria-hidden":"true"}},[t._v("#")]),t._v(" NETRON")]),t._v(" "),n("p",[t._v("You can also show your model in the "),n("strong",[t._v("NETRON APPLICATION")]),t._v(" "),n("a",{attrs:{href:"https://github.com/lutzroeder/netron",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://github.com/lutzroeder/netron"),n("OutboundLink")],1),t._v(" as a graph. For the pytorch "),n("code",[t._v("learn.save()")]),t._v(" the application show error for me, but you can export your model to the "),n("code",[t._v("ONNX")]),t._v(" format, and open in the application.")]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("dummy_input "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("randn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("224")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("224")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cpu"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# the size of your input")]),t._v("\n\ntorch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("onnx"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("export"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("learn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cpu"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                  dummy_input"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                  "),n("span",{pre:!0,attrs:{class:"token string"}},[t._v('"./models/resnet34-entire-model.onnx"')]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                  verbose"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[n("img",{attrs:{src:s(228),alt:"1552575612810"}})]),t._v(" "),n("h3",{attrs:{id:"batch-normalization"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#batch-normalization","aria-hidden":"true"}},[t._v("#")]),t._v(" Batch Normalization "),n("cl",{attrs:{i:"https://towardsdatascience.com/batch-normalization-in-neural-networks-1ac91516821c"}}),t._v(" "),n("cl",{attrs:{i:"https://arxiv.org/abs/1502.03167",t:"paper"}}),t._v(" "),n("cl",{attrs:{i:"https://www.youtube.com/watch?v=nUUqwaxLnWs",t:"video"}})],1),t._v(" "),n("p",[t._v("Batch normalization is a type of layer for the neural network that make loss surface smootherby normalizing parameters inside hidden layers, like you do with the input layer.")]),t._v(" "),n("p",[n("img",{attrs:{src:s(229),alt:"1552580302141"}})]),t._v(" "),n("p",[t._v("Bath Normalization reduce problem when input changes, so the loss function is more stable and less bumpy.")]),t._v(" "),n("div",{staticClass:"warning custom-block"},[n("p",{staticClass:"custom-block-title"},[t._v("Batch normalization doesnâ€™t  reducing internal covariate shift")]),t._v(" "),n("p",[n("strong",[t._v("Internal Covariate shift")]),t._v(" refers to change in the distribution of layer inputs caused by updates to the preceding layers. (where for example you put different style of images next time)")]),t._v(" "),n("p",[t._v("Last papers shows that Batch Normalization doesnâ€™t reduce ICS like in the original paper.  https://arxiv.org/pdf/1805.11604.pdf](https://arxiv.org/pdf/1805.11604.pdf)")])]),t._v(" "),n("p",[t._v("Benefits:")]),t._v(" "),n("ul",[n("li",[t._v("We can use higher learning rates because batch normalization makes sure that thereâ€™s no activation thatâ€™s gone really high or really low. And by that, things that previously couldnâ€™t get to train, it will start to train.")]),t._v(" "),n("li",[t._v("It reduces overfitting because it has a slight regularization effects.")])]),t._v(" "),n("p",[t._v("How it is calculated:")]),t._v(" "),n("ol",[n("li",[t._v("We get mini-batch")]),t._v(" "),n("li",[t._v("Calculate mean ("),n("code",[t._v("e")]),t._v(") anv variance ("),n("code",[t._v("var")]),t._v(") of the mini-batch")]),t._v(" "),n("li",[t._v("normalize the output "),n("code",[t._v("y=(x-e)/sqrt(var)")])]),t._v(" "),n("li",[t._v("Scale and shift the output using own parameters  "),n("strong",[t._v("Î³")]),t._v(" and "),n("strong",[t._v("Î²")]),t._v(" . This are wieghts that are also larned during a backward optimalization. We also need to scale and shift the normalized values otherwise just normalizing a layer would limit the layer in terms of what it can represent.")])]),t._v(" "),n("p",[n("img",{attrs:{src:s(230),alt:"img"}})]),t._v(" "),n("h3",{attrs:{id:"dropout"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#dropout","aria-hidden":"true"}},[t._v("#")]),t._v(" Dropout "),n("cl",{attrs:{i:"https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf",t:"paper"}}),t._v(" "),n("cl",{attrs:{i:"https://www.youtube.com/watch?v=ARq74QuavAo",t:"video"}})],1),t._v(" "),n("p",[n("img",{attrs:{src:s(231),alt:"1552583126804"}})]),t._v(" "),n("p",[t._v("Dropout is a tregulariation method that for reducing overfitting in neural network, by preventing complex co-adaptaions on training data.  At random, we throw away some "),n("strong",[t._v("percentage of the activations")]),t._v(",  "),n("red",[t._v(" After we finish traiing we remove dropout on the activation, because we wanted to be accurate.")]),t._v(" Dropout use Bernoulli distribution to remove some activations.")],1),t._v(" "),n("ul",[n("li",[t._v("It helps working with overfitting. If we over fit some parts are recognizing particular image. If we turn off them during training the network the network will avoid this behaviour.")])]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[t._v("torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("manual_seed"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nm "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Dropout"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("p"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v(".5")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# in 50% probability return 0.")]),t._v("\n"),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" torch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("randn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nm"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("input")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),n("p",[n("img",{attrs:{src:s(232),alt:"1552588690527"}})]),t._v(" "),n("h3",{attrs:{id:"show-heatmap"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#show-heatmap","aria-hidden":"true"}},[t._v("#")]),t._v(" .show_heatmap()")]),t._v(" "),n("p",[t._v("Pytorch alows you to "),n("code",[t._v("hook")]),t._v(" the layer and store some information before. In the "),n("code",[t._v("resnet34")]),t._v(" if you look at the lasst layer you will find that last linear "),n("code",[t._v("[1,37]")]),t._v(" it is your layer for classification (cat/dogs breeds),  previous layers are also flat layers with classification "),n("code",[t._v("[512]")]),t._v(", this is the end of "),n("code",[t._v("resnet34")]),t._v(" model.")]),t._v(" "),n("p",[t._v("We have two groups of layers "),n("code",[t._v("learn.model[0]")]),t._v(", and "),n("code",[t._v("learn.model[1]")]),t._v(". We can get first layer with the last "),n("code",[t._v("Conv2d")]),t._v("layer, and "),n("code",[t._v("BatchNorm2d")]),t._v(" that size is  "),n("code",[t._v("[1,512,11,11]")]),t._v(" , and usign "),n("code",[t._v("hook")]),t._v(" and get what is stored in the output for that category ("),n("code",[t._v("preds[0,int(cat)].backward()")]),t._v("), next we get what was stored in the "),n("code",[t._v("hook_a.stored[0].cpu()")]),t._v(" variable, and this is our heatmap.")]),t._v(" "),n("p",[n("img",{attrs:{src:s(233),alt:"1552590896874"}})]),t._v(" "),n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("show_heatmap")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("learn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    m "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" learn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("eval")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# set mode to evaluation mode")]),t._v("\n    xb"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("_ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" learn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("one_item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    \n    xb_im "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Image"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("denorm"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("xb"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    \n    \n    xb "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" xb"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cuda"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("xb"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" fastai"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("callbacks"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hooks "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" hook_output\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("hooked_backward")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cat"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" hook_output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("m"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" hook_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" \n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" hook_output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("m"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" grad"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" hook_g"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(m[0])")]),t._v("\n                preds "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" m"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("xb"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(preds.shape)")]),t._v("\n                preds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("backward"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hook_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stored"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" hook_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("hook_g\n    \n    hook_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("hook_g "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" hooked_backward"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    acts  "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" hook_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stored"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cpu"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    avg_acts "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" acts"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("acts"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("avg_acts"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("show_heatmap")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hm"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("ax "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("subplots"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        xb_im"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("width"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("height "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" xb_im"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape\n        ax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("imshow"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hm"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                  alpha"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" extent"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("width"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("height"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                  interpolation"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'bilinear'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cmap"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'magma'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n    show_heatmap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("avg_acts"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nx"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train_ds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5004")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nshow_heatmap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("learn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("     \n")])])]),n("full-code",[n("div",{staticClass:"language-python extra-class"},[n("pre",{pre:!0,attrs:{class:"language-python"}},[n("code",[n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" fastai"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("vision "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v("\n\nbs "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("64")]),t._v("\npath "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" untar_data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("URLs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("PETS"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'images'")]),t._v("\nsize "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("324")]),t._v("\n\ndata "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ImageList"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from_folder"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("path"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split_by_rand_pct"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" seed"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("label_from_re"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("r'([^/]+)_\\d+.jpg$'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("transform"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("get_transforms"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" size"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("352")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("databunch"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bs"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("bs"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("normalize"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("imagenet_stats"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlearn "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cnn_learner"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                   models"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("resnet34"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                   metrics"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("error_rate"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                   bn_final"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nlearn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit_one_cycle"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                    "),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("slice")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                    pct_start"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlearn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("unfreeze"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nlearn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fit_one_cycle"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" max_lr"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("slice")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("1e")]),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" pct_start"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.8")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n                    \n"),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("show_heatmap")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("learn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    m "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" learn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("model"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("eval")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# set mode to evaluation mode")]),t._v("\n    xb"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("_ "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" learn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("one_item"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    \n    xb_im "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Image"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("denorm"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("xb"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    \n    \n    xb "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" xb"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cuda"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("xb"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" fastai"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("callbacks"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hooks "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" hook_output\n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("hooked_backward")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cat"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" hook_output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("m"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" hook_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" \n            "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" hook_output"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("m"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" grad"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" hook_g"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(m[0])")]),t._v("\n                preds "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" m"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("xb"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n                "),n("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# print(preds.shape)")]),t._v("\n                preds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("int")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cat"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("backward"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hook_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stored"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" hook_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("hook_g\n    \n    hook_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("hook_g "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" hooked_backward"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    acts  "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" hook_a"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stored"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cpu"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    avg_acts "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" acts"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mean"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("acts"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("avg_acts"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    "),n("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),n("span",{pre:!0,attrs:{class:"token function"}},[t._v("show_heatmap")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hm"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("ax "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" plt"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("subplots"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        xb_im"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        _"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("width"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("height "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" xb_im"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("shape\n        ax"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("imshow"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("hm"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" \n                  alpha"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0.6")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" extent"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("width"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("height"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                  interpolation"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'bilinear'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" cmap"),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),n("span",{pre:!0,attrs:{class:"token string"}},[t._v("'magma'")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        \n    show_heatmap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("avg_acts"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nx"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y "),n("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("train_ds"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),n("span",{pre:!0,attrs:{class:"token number"}},[t._v("5004")]),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\nshow_heatmap"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("learn"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("x"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("y"),n("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])])]),t._v(" "),n("p",[n("img",{attrs:{src:s(234),alt:"1552593708692"}})]),t._v(" "),n("p",[n("img",{attrs:{src:s(235),alt:"1552593695073"}})]),t._v(" "),n("h4",{attrs:{id:"another-layer"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#another-layer","aria-hidden":"true"}},[t._v("#")]),t._v(" Another layer")]),t._v(" "),n("p",[t._v("Letâ€™s now change "),n("code",[t._v("m[0]")]),t._v(" to "),n("code",[t._v("m[0][1]")]),t._v(". This is a first layer of your network (after "),n("code",[t._v("BatchNorm2d")]),t._v(").  What you can see that first layer regnozie edges of the pet.")]),t._v(" "),n("p",[n("img",{attrs:{src:s(236),alt:"1552594605148"}})])],1)},[],!1,null,null,null);a.default=e.exports},457:function(t,a,s){t.exports=s.p+"assets/img/1552571621488.21f58e94.png"}}]);